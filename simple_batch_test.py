#!/usr/bin/env python3
"""
æ‰¹é‡å¤„ç†æµ‹è¯• - ä½¿ç”¨batch_doc_analyzeæŒ‰é¡µæ•°åˆ†æ‰¹å¤„ç†å¤šä¸ªPDF
"""
import os
import sys
import time
from pathlib import Path
from datetime import datetime

# æ·»åŠ mineruæ¨¡å—åˆ°è·¯å¾„
sys.path.insert(0, '/home/ubuntu/MinerU')

from mineru.cli.common import convert_pdf_bytes_to_bytes_by_pypdfium2, prepare_env, read_fn
from mineru.data.data_reader_writer import FileBasedDataWriter
from mineru.backend.vlm.vlm_analyze import batch_doc_analyze
import pypdfium2  # ç”¨äºè·å–PDFé¡µæ•°


def get_pdf_files(demo_dir):
    """è·å–demoç›®å½•ä¸­çš„æ‰€æœ‰PDFæ–‡ä»¶"""
    pdf_files = []
    demo_path = Path(demo_dir)

    if not demo_path.exists():
        print(f"Demoç›®å½•ä¸å­˜åœ¨: {demo_dir}")
        return pdf_files

    # æŸ¥æ‰¾æ‰€æœ‰PDFæ–‡ä»¶
    for pdf_file in demo_path.glob("*.pdf"):
        if pdf_file.is_file():
            pdf_files.append(pdf_file)

    return sorted(pdf_files)


def process_pdf_and_get_info(pdf_path):
    """
    å¤„ç†PDFæ–‡ä»¶ï¼šè·å–é¡µæ•°å¹¶è½¬æ¢ä¸ºå­—èŠ‚æ•°æ®
    åœ¨ä¸€ä¸ªå‡½æ•°ä¸­å®Œæˆæ‰€æœ‰PDFç›¸å…³æ“ä½œï¼Œå‡å°‘é‡å¤è¯»å–
    è¿”å›: (page_count, pdf_bytes, is_valid, error_message)
    """
    try:
        # ç¬¬ä¸€æ­¥ï¼šå°è¯•è¯»å–PDFå­—èŠ‚æ•°æ®
        pdf_bytes = read_fn(pdf_path)

        # ç¬¬äºŒæ­¥ï¼šå°è¯•è·å–é¡µæ•°
        pdf_document = pypdfium2.PdfDocument(pdf_bytes)
        page_count = len(pdf_document)
        pdf_document.close()

        # ç¬¬ä¸‰æ­¥ï¼šè½¬æ¢ä¸ºå¤„ç†ç”¨çš„å­—èŠ‚æ•°æ®
        processed_pdf_bytes = convert_pdf_bytes_to_bytes_by_pypdfium2(pdf_bytes, 0, None)

        return page_count, processed_pdf_bytes, True, None

    except Exception as e:
        error_msg = str(e)
        print(f"âš ï¸ å¤„ç† {pdf_path.name} å¤±è´¥: {error_msg}")

        # æ ¹æ®é”™è¯¯ç±»å‹æä¾›æ›´å…·ä½“çš„æç¤º
        if "password" in error_msg.lower() or "encrypted" in error_msg.lower():
            error_msg = f"PDFæ–‡ä»¶å·²åŠ å¯†æˆ–éœ€è¦å¯†ç : {error_msg}"
        elif "corrupted" in error_msg.lower() or "damaged" in error_msg.lower():
            error_msg = f"PDFæ–‡ä»¶å·²æŸå: {error_msg}"
        elif "invalid" in error_msg.lower():
            error_msg = f"æ— æ•ˆçš„PDFæ–‡ä»¶: {error_msg}"

        return 0, None, False, error_msg


def get_pdf_page_count_safe(pdf_path):
    """å®‰å…¨è·å–PDFæ–‡ä»¶çš„é¡µæ•°ï¼Œå¤„ç†å¼‚å¸¸æƒ…å†µ"""
    try:
        # åªè¯»å–é¡µæ•°ï¼Œä¸å¤„ç†å­—èŠ‚ï¼Œé¿å…å†…å­˜å ç”¨
        pdf_bytes = read_fn(pdf_path)
        pdf_document = pypdfium2.PdfDocument(pdf_bytes)
        page_count = len(pdf_document)
        pdf_document.close()
        return page_count, True, None
    except Exception as e:
        error_msg = str(e)

        # æ ¹æ®é”™è¯¯ç±»å‹æä¾›æ›´å…·ä½“çš„æç¤º
        if "password" in error_msg.lower() or "encrypted" in error_msg.lower():
            error_msg = f"PDFæ–‡ä»¶å·²åŠ å¯†æˆ–éœ€è¦å¯†ç : {error_msg}"
        elif "corrupted" in error_msg.lower() or "damaged" in error_msg.lower():
            error_msg = f"PDFæ–‡ä»¶å·²æŸå: {error_msg}"
        elif "invalid" in error_msg.lower():
            error_msg = f"æ— æ•ˆçš„PDFæ–‡ä»¶: {error_msg}"

        return 0, False, error_msg


def process_single_batch(batch_idx, batch_files, estimated_pages, output_base_dir, backend, overall_stats):
    """
    å¤„ç†å•ä¸ªæ‰¹æ¬¡
    è¿”å›: (success, actual_pages_processed)
    """
    try:
        print(f"\n--- å¤„ç†æ‰¹æ¬¡ {batch_idx} ---")
        print(f"æ–‡ä»¶: {len(batch_files)} ä¸ª")
        print(f"é¢„ä¼°é¡µæ•°: {estimated_pages} é¡µ")
        print(f"æ–‡ä»¶å: {', '.join([f.name for f in batch_files])}")

        # å®æ—¶å‡†å¤‡PDFæ•°æ®
        pdf_bytes_list = []
        pdf_file_names = []
        actual_pages_in_batch = 0

        print(f"ğŸ“– å®æ—¶åŠ è½½æ‰¹æ¬¡ {batch_idx} PDFæ–‡ä»¶...")

        for i, pdf_path in enumerate(batch_files):
            print(f"  ğŸ“„ åŠ è½½ {i+1}/{len(batch_files)}: {pdf_path.name}")

            try:
                # å®æ—¶è¯»å–å’Œå¤„ç†PDF
                pdf_bytes = read_fn(pdf_path)
                pdf_bytes = convert_pdf_bytes_to_bytes_by_pypdfium2(pdf_bytes, 0, None)

                # éªŒè¯å¤„ç†åçš„æ•°æ®
                if pdf_bytes is None or len(pdf_bytes) == 0:
                    print(f"    âŒ è½¬æ¢å¤±è´¥ï¼Œè·³è¿‡æ–‡ä»¶")
                    continue

                pdf_bytes_list.append(pdf_bytes)
                pdf_file_names.append(pdf_path.stem)

                # è·å–å®é™…é¡µæ•°
                try:
                    temp_pdf = pypdfium2.PdfDocument(read_fn(pdf_path))
                    actual_page_count = len(temp_pdf)
                    temp_pdf.close()
                    actual_pages_in_batch += actual_page_count
                    print(f"    âœ… æˆåŠŸ: {actual_page_count} é¡µ")
                except:
                    print(f"    âš ï¸ æ— æ³•ç¡®è®¤é¡µæ•°ï¼Œè·³è¿‡")
                    continue

            except Exception as e:
                print(f"    âŒ å¤„ç†å¤±è´¥: {e}")
                continue

        if not pdf_bytes_list:
            print(f"  âŒ æ‰¹æ¬¡ {batch_idx} æ²¡æœ‰æœ‰æ•ˆæ–‡ä»¶ï¼Œè·³è¿‡")
            return False

        print(f"  ğŸ“¦ æ‰¹æ¬¡ {batch_idx} å®é™…åŠ è½½: {len(pdf_bytes_list)}/{len(batch_files)} æ–‡ä»¶, {actual_pages_in_batch} é¡µ")

        # åˆ›å»ºå›¾åƒå†™å…¥å™¨
        image_writers = []
        output_dirs = []

        print(f"ğŸ“ å‡†å¤‡æ‰¹æ¬¡ {batch_idx} è¾“å‡ºç›®å½•...")
        for pdf_file_name in pdf_file_names:
            local_image_dir, local_md_dir = prepare_env(output_base_dir / pdf_file_name, pdf_file_name, "vlm")
            image_writer = FileBasedDataWriter(local_image_dir)
            image_writers.append(image_writer)
            output_dirs.append((local_image_dir, local_md_dir))
            print(f"  ğŸ“‚ {pdf_file_name}: {local_md_dir}")

        print(f"ğŸ”„ å¤„ç†æ‰¹æ¬¡ {batch_idx}...")
        batch_start_time = time.time()

        # ä½¿ç”¨batch_doc_analyzeæ‰¹é‡å¤„ç†
        all_middle_json, _ = batch_doc_analyze(
            pdf_bytes_list=pdf_bytes_list,
            image_writer_list=image_writers,
            backend=backend[4:],  # å»æ‰"vlm-"å‰ç¼€
            server_url=None
        )

        batch_end_time = time.time()
        batch_processing_time = batch_end_time - batch_start_time

        print(f"âœ… æ‰¹æ¬¡ {batch_idx} å¤„ç†å®Œæˆ! ç”¨æ—¶: {batch_processing_time:.2f} ç§’")

        # ç»Ÿè®¡å½“å‰æ‰¹æ¬¡ç»“æœ
        batch_pages_processed = 0
        batch_files_generated = 0

        for i, (pdf_file_name, middle_json) in enumerate(zip(pdf_file_names, all_middle_json)):
            if isinstance(middle_json, dict) and "pdf_info" in middle_json:
                pages = len(middle_json["pdf_info"])
                batch_pages_processed += pages
                print(f"  ğŸ“„ {pdf_file_name}: {pages} é¡µ")

                # ç»Ÿè®¡ç”Ÿæˆçš„æ–‡ä»¶æ•°é‡
                local_image_dir, local_md_dir = output_dirs[i]
                if Path(local_md_dir).exists():
                    output_files = list(Path(local_md_dir).rglob("*"))
                    batch_files_generated += len(output_files)
                    print(f"     ç”Ÿæˆæ–‡ä»¶: {len(output_files)} ä¸ª")

        # æ›´æ–°æ€»ä½“ç»Ÿè®¡
        overall_stats['total_files_processed'] += len(pdf_bytes_list)
        overall_stats['total_pages_processed'] += batch_pages_processed
        overall_stats['total_files_generated'] += batch_files_generated

        print(f"ğŸ“Š æ‰¹æ¬¡ {batch_idx} ç»Ÿè®¡:")
        print(f"  å¤„ç†æ–‡ä»¶: {len(pdf_bytes_list)} ä¸ª")
        print(f"  å¤„ç†é¡µæ•°: {batch_pages_processed} é¡µ")
        print(f"  ç”Ÿæˆæ–‡ä»¶: {batch_files_generated} ä¸ª")
        print(f"  å¤„ç†é€Ÿåº¦: {batch_pages_processed/batch_processing_time:.2f} é¡µ/ç§’")

        return True

    except Exception as e:
        print(f"âŒ æ‰¹æ¬¡ {batch_idx} å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """æ‰¹é‡å¤„ç†æµ‹è¯•"""
    print("ğŸš€ æ‰¹é‡å¤„ç†æµ‹è¯• (batch_doc_analyze - æŒ‰é¡µæ•°åˆ†æ‰¹)")
    print(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*80)

    # è·å–æ‰¹æ¬¡å¤§å°ï¼ˆç¯å¢ƒå˜é‡æˆ–é»˜è®¤å€¼ï¼‰
    batch_size = int(os.environ.get('DEFAULT_BATCH_SIZE', '384'))
    print(f"ğŸ“¦ æ‰¹æ¬¡å¤§å°è®¾ç½®: {batch_size} é¡µ/æ‰¹æ¬¡")

    # è®¾ç½®è·¯å¾„
    demo_dir = "/home/ubuntu/MinerU/demo/pdfs"
    output_base_dir = Path("/home/ubuntu/MinerU/batch_vs_step_batch")
    output_base_dir.mkdir(exist_ok=True)

    # è·å–PDFæ–‡ä»¶
    pdf_files = get_pdf_files(demo_dir)
    if not pdf_files:
        print("âŒ æœªæ‰¾åˆ°PDFæ–‡ä»¶")
        return

    # é™åˆ¶æµ‹è¯•æ–‡ä»¶æ•°é‡ï¼ˆå¯é€‰ï¼‰
    max_files = int(os.environ.get('MAX_FILES', str(len(pdf_files))))
    test_pdf_files = pdf_files[:max_files]

    print(f"\nğŸ“„ å‘ç°PDFæ–‡ä»¶ ({len(test_pdf_files)}ä¸ª):")
    total_size = 0
    for i, pdf_file in enumerate(test_pdf_files, 1):
        file_size = pdf_file.stat().st_size / 1024 / 1024  # MB
        total_size += file_size
        print(f"  {i}. {pdf_file.name} ({file_size:.2f} MB)")
    print(f"æ€»å¤§å°: {total_size:.2f} MB")

    # ä½¿ç”¨vlm-vllm-engineåç«¯
    backend = "vlm-vllm-engine"

    print(f"\nğŸ¯ åŠ¨æ€åˆ†æ‰¹å¤„ç†æ¨¡å¼:")
    print(f"  æ–‡ä»¶æ•°é‡: {len(test_pdf_files)}")
    print(f"  æ‰¹æ¬¡å¤§å°: {batch_size} é¡µ/æ‰¹æ¬¡")

    try:
        total_start_time = time.time()
        overall_stats = {
            'total_files_processed': 0,
            'total_pages_processed': 0,
            'total_files_generated': 0,
            'batch_count': 0,
            'total_files_attempted': 0,
            'failed_files': 0
        }

        print(f"\nğŸ”„ å¼€å§‹åŠ¨æ€åˆ†æ‰¹å¤„ç†...")
        print(f"åç«¯: {backend}")

        # åŠ¨æ€æ‰¹æ¬¡å¤„ç†
        current_batch_files = []
        current_batch_pages = 0
        batch_idx = 0

        # ä½¿ç”¨ for i in range å¾ªç¯é€æ­¥å¤„ç†æ–‡ä»¶
        for i in range(len(test_pdf_files)):
            pdf_file = test_pdf_files[i]
            print(f"\nğŸ“„ å¤„ç†æ–‡ä»¶ {i+1}/{len(test_pdf_files)}: {pdf_file.name}")

            # è·å–é¡µæ•°ï¼ˆå¦‚æœå¤±è´¥åˆ™è·³è¿‡ï¼‰
            page_count, is_valid, error_msg = get_pdf_page_count_safe(pdf_file)
            overall_stats['total_files_attempted'] += 1

            if not is_valid or page_count == 0:
                print(f"  âŒ è·³è¿‡æ–‡ä»¶: {error_msg}")
                overall_stats['failed_files'] += 1
                continue

            print(f"  âœ… é¡µæ•°: {page_count}")

            # åˆ¤æ–­æ˜¯å¦éœ€è¦å¼€å§‹æ–°æ‰¹æ¬¡
            if (len(current_batch_files) > 0 and current_batch_pages + page_count > batch_size) or page_count >= batch_size:
                # å…ˆå¤„ç†å½“å‰æ‰¹æ¬¡
                if current_batch_files:
                    batch_idx += 1
                    success = process_single_batch(
                        batch_idx,
                        current_batch_files,
                        current_batch_pages,
                        output_base_dir,
                        backend,
                        overall_stats
                    )
                    if success:
                        overall_stats['batch_count'] += 1

                current_batch_files = []
                current_batch_pages = 0

            # å¦‚æœæ˜¯è¶…å¤§æ–‡ä»¶ï¼Œå•ç‹¬å¤„ç†
            if page_count >= batch_size:
                batch_idx += 1
                success = process_single_batch(
                    batch_idx,
                    [pdf_file],
                    page_count,
                    output_base_dir,
                    backend,
                    overall_stats
                )
                if success:
                    overall_stats['batch_count'] += 1
                continue

            # æ·»åŠ åˆ°å½“å‰æ‰¹æ¬¡
            current_batch_files.append(pdf_file)
            current_batch_pages += page_count
            print(f"  ğŸ“¦ åŠ å…¥å½“å‰æ‰¹æ¬¡: {len(current_batch_files)} æ–‡ä»¶, {current_batch_pages} é¡µ")

        # å¤„ç†æœ€åä¸€ä¸ªæ‰¹æ¬¡
        if current_batch_files:
            batch_idx += 1
            success = process_single_batch(
                batch_idx,
                current_batch_files,
                current_batch_pages,
                output_base_dir,
                backend,
                overall_stats
            )
            if success:
                overall_stats['batch_count'] += 1

        total_end_time = time.time()
        total_processing_time = total_end_time - total_start_time

        print(f"\nğŸ‰ åŠ¨æ€åˆ†æ‰¹å¤„ç†å®Œæˆ!")
        print(f"\nğŸ¯ æ€»ä½“æ€§èƒ½ç»Ÿè®¡:")
        print(f"  åŸå§‹PDFæ•°é‡: {len(test_pdf_files)} ä¸ª")
        print(f"  å°è¯•å¤„ç†: {overall_stats['total_files_attempted']} ä¸ª")
        print(f"  å¤„ç†å¤±è´¥: {overall_stats['failed_files']} ä¸ª")
        print(f"  æˆåŠŸå¤„ç†PDFæ•°é‡: {overall_stats['total_files_processed']} ä¸ª")
        print(f"  æ€»æ‰¹æ¬¡æ•°: {overall_stats['batch_count']}")
        print(f"  æ€»é¡µæ•°: {overall_stats['total_pages_processed']}")
        print(f"  æ€»å¤„ç†æ—¶é—´: {total_processing_time:.2f} ç§’")
        if overall_stats['total_files_processed'] > 0:
            print(f"  å¹³å‡æ¯PDF: {total_processing_time/overall_stats['total_files_processed']:.2f} ç§’")
        if overall_stats['total_pages_processed'] > 0:
            print(f"  å¹³å‡æ¯é¡µ: {total_processing_time/overall_stats['total_pages_processed']:.2f} ç§’")
            print(f"  å¤„ç†é€Ÿåº¦: {overall_stats['total_pages_processed']/total_processing_time:.2f} é¡µ/ç§’")
        print(f"  æ€»ç”Ÿæˆæ–‡ä»¶: {overall_stats['total_files_generated']} ä¸ª")
        if overall_stats['batch_count'] > 0:
            print(f"  å¹³å‡æ¯æ‰¹æ¬¡: {total_processing_time/overall_stats['batch_count']:.2f} ç§’")

        # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
        results_file = output_base_dir / "batch_results.txt"
        with open(results_file, 'w', encoding='utf-8') as f:
            f.write(f"åŠ¨æ€åˆ†æ‰¹å¤„ç†æµ‹è¯•ç»“æœ\n")
            f.write(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"æ‰¹æ¬¡å¤§å°: {batch_size} é¡µ/æ‰¹æ¬¡\n")
            f.write(f"åŸå§‹æ–‡ä»¶æ•°: {len(test_pdf_files)}\n")
            f.write(f"å°è¯•å¤„ç†æ•°: {overall_stats['total_files_attempted']}\n")
            f.write(f"å¤„ç†å¤±è´¥æ•°: {overall_stats['failed_files']}\n")
            f.write(f"æˆåŠŸå¤„ç†æ–‡ä»¶æ•°: {overall_stats['total_files_processed']}\n")
            f.write(f"æ€»æ‰¹æ¬¡æ•°: {overall_stats['batch_count']}\n")
            f.write(f"æ€»å¤„ç†æ—¶é—´: {total_processing_time:.2f} ç§’\n")
            if overall_stats['total_files_processed'] > 0:
                f.write(f"å¹³å‡æ¯PDF: {total_processing_time/overall_stats['total_files_processed']:.2f} ç§’\n")
            if overall_stats['total_pages_processed'] > 0:
                f.write(f"å¤„ç†é€Ÿåº¦: {overall_stats['total_pages_processed']/total_processing_time:.2f} é¡µ/ç§’\n")
            f.write(f"æ€»ç”Ÿæˆæ–‡ä»¶: {overall_stats['total_files_generated']} ä¸ª\n")

        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {results_file}")
        print(f"ğŸ è¾“å‡ºç›®å½•: {output_base_dir}")
        print(f"ğŸ‰ åˆ†æ‰¹å¤„ç†æµ‹è¯•å®Œæˆ!")

    except Exception as e:
        print(f"âŒ åˆ†æ‰¹å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()