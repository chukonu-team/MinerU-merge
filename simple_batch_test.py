#!/usr/bin/env python3
"""
æ‰¹é‡å¤„ç†æµ‹è¯• - ä½¿ç”¨batch_doc_analyzeæŒ‰é¡µæ•°åˆ†æ‰¹å¤„ç†å¤šä¸ªPDF
"""
import os
import sys
import time
from pathlib import Path
from datetime import datetime

# æ·»åŠ mineruæ¨¡å—åˆ°è·¯å¾„
sys.path.insert(0, '/home/ubuntu/MinerU')

from mineru.cli.common import convert_pdf_bytes_to_bytes_by_pypdfium2, prepare_env, read_fn
from mineru.data.data_reader_writer import FileBasedDataWriter
from mineru.backend.vlm.vlm_analyze import batch_doc_analyze
import pypdfium2  # ç”¨äºè·å–PDFé¡µæ•°


def get_pdf_files(demo_dir):
    """è·å–demoç›®å½•ä¸­çš„æ‰€æœ‰PDFæ–‡ä»¶"""
    pdf_files = []
    demo_path = Path(demo_dir)

    if not demo_path.exists():
        print(f"Demoç›®å½•ä¸å­˜åœ¨: {demo_dir}")
        return pdf_files

    # æŸ¥æ‰¾æ‰€æœ‰PDFæ–‡ä»¶
    for pdf_file in demo_path.glob("*.pdf"):
        if pdf_file.is_file():
            pdf_files.append(pdf_file)

    return sorted(pdf_files)


def get_pdf_page_count(pdf_path):
    """è·å–PDFæ–‡ä»¶çš„é¡µæ•°"""
    try:
        pdf_bytes = read_fn(pdf_path)
        # ä½¿ç”¨pypdfium2è®¡ç®—é¡µæ•°
        pdf_document = pypdfium2.PdfDocument(pdf_bytes)
        page_count = len(pdf_document)
        pdf_document.close()
        return page_count
    except Exception as e:
        print(f"âš ï¸ æ— æ³•è·å– {pdf_path.name} çš„é¡µæ•°: {e}")
        return 0


def create_batches_by_pages(pdf_files, batch_size):
    """
    æ ¹æ®é¡µæ•°åˆ›å»ºæ‰¹æ¬¡
    :param pdf_files: PDFæ–‡ä»¶åˆ—è¡¨
    :param batch_size: æ¯æ‰¹æ¬¡æœ€å¤§é¡µæ•°
    :return: æ‰¹æ¬¡åˆ—è¡¨ï¼Œæ¯ä¸ªæ‰¹æ¬¡åŒ…å«æ–‡ä»¶åˆ—è¡¨å’Œæ€»é¡µæ•°
    """
    batches = []
    current_batch = []
    current_batch_pages = 0

    print(f"ğŸ“¦ æŒ‰é¡µæ•°åˆ†æ‰¹ (æ¯æ‰¹æœ€å¤š {batch_size} é¡µ):")

    for i, pdf_file in enumerate(pdf_files):
        page_count = get_pdf_page_count(pdf_file)

        # å¦‚æœå•ä¸ªæ–‡ä»¶å°±è¶…è¿‡æ‰¹æ¬¡å¤§å°ï¼Œå•ç‹¬ä½œä¸ºä¸€æ‰¹
        if page_count >= batch_size:
            if current_batch:  # å…ˆå¤„ç†å½“å‰æ‰¹æ¬¡
                batches.append({
                    'files': current_batch.copy(),
                    'total_pages': current_batch_pages,
                    'file_names': [f.stem for f in current_batch]
                })
                print(f"  æ‰¹æ¬¡ {len(batches)}: {len(current_batch)} ä¸ªæ–‡ä»¶, {current_batch_pages} é¡µ")
                current_batch = []
                current_batch_pages = 0

            # å¤§æ–‡ä»¶å•ç‹¬ä¸€æ‰¹
            batches.append({
                'files': [pdf_file],
                'total_pages': page_count,
                'file_names': [pdf_file.stem]
            })
            print(f"  æ‰¹æ¬¡ {len(batches)}: {pdf_file.name}, {page_count} é¡µ (å¤§æ–‡ä»¶å•ç‹¬æ‰¹æ¬¡)")
            continue

        # å¦‚æœå½“å‰æ‰¹æ¬¡åŠ ä¸Šè¿™ä¸ªæ–‡ä»¶ä¼šè¶…è¿‡é™åˆ¶ï¼Œå…ˆå¤„ç†å½“å‰æ‰¹æ¬¡
        if current_batch_pages + page_count > batch_size:
            batches.append({
                'files': current_batch.copy(),
                'total_pages': current_batch_pages,
                'file_names': [f.stem for f in current_batch]
            })
            print(f"  æ‰¹æ¬¡ {len(batches)}: {len(current_batch)} ä¸ªæ–‡ä»¶, {current_batch_pages} é¡µ")
            current_batch = []
            current_batch_pages = 0

        # æ·»åŠ åˆ°å½“å‰æ‰¹æ¬¡
        current_batch.append(pdf_file)
        current_batch_pages += page_count

    # å¤„ç†æœ€åä¸€ä¸ªæ‰¹æ¬¡
    if current_batch:
        batches.append({
            'files': current_batch,
            'total_pages': current_batch_pages,
            'file_names': [f.stem for f in current_batch]
        })
        print(f"  æ‰¹æ¬¡ {len(batches)}: {len(current_batch)} ä¸ªæ–‡ä»¶, {current_batch_pages} é¡µ")

    return batches


def main():
    """æ‰¹é‡å¤„ç†æµ‹è¯•"""
    print("ğŸš€ æ‰¹é‡å¤„ç†æµ‹è¯• (batch_doc_analyze - æŒ‰é¡µæ•°åˆ†æ‰¹)")
    print(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*80)

    # è·å–æ‰¹æ¬¡å¤§å°ï¼ˆç¯å¢ƒå˜é‡æˆ–é»˜è®¤å€¼ï¼‰
    batch_size = int(os.environ.get('DEFAULT_BATCH_SIZE', '384'))
    print(f"ğŸ“¦ æ‰¹æ¬¡å¤§å°è®¾ç½®: {batch_size} é¡µ/æ‰¹æ¬¡")

    # è®¾ç½®è·¯å¾„
    demo_dir = "/home/ubuntu/MinerU/demo/pdfs"
    output_base_dir = Path("/home/ubuntu/MinerU/batch_vs_step_batch")
    output_base_dir.mkdir(exist_ok=True)

    # è·å–PDFæ–‡ä»¶
    pdf_files = get_pdf_files(demo_dir)
    if not pdf_files:
        print("âŒ æœªæ‰¾åˆ°PDFæ–‡ä»¶")
        return

    # é™åˆ¶æµ‹è¯•æ–‡ä»¶æ•°é‡ï¼ˆå¯é€‰ï¼‰
    max_files = int(os.environ.get('MAX_FILES', str(len(pdf_files))))
    test_pdf_files = pdf_files[:max_files]

    print(f"\nğŸ“„ å‘ç°PDFæ–‡ä»¶ ({len(test_pdf_files)}ä¸ª):")
    total_size = 0
    total_pages = 0
    for i, pdf_file in enumerate(test_pdf_files, 1):
        file_size = pdf_file.stat().st_size / 1024 / 1024  # MB
        page_count = get_pdf_page_count(pdf_file)
        total_size += file_size
        total_pages += page_count
        print(f"  {i}. {pdf_file.name} ({file_size:.2f} MB, {page_count} é¡µ)")
    print(f"æ€»å¤§å°: {total_size:.2f} MB")
    print(f"æ€»é¡µæ•°: {total_pages} é¡µ")

    # ä½¿ç”¨vlm-vllm-engineåç«¯
    backend = "vlm-vllm-engine"

    # åˆ›å»ºæ‰¹æ¬¡
    batches = create_batches_by_pages(test_pdf_files, batch_size)
    if not batches:
        print("âŒ æ— æ³•åˆ›å»ºå¤„ç†æ‰¹æ¬¡")
        return

    print(f"\nğŸ¯ åˆ†æ‰¹ç»Ÿè®¡:")
    print(f"  æ€»æ‰¹æ¬¡æ•°: {len(batches)}")
    print(f"  æ€»æ–‡ä»¶æ•°: {len(test_pdf_files)}")
    print(f"  æ€»é¡µæ•°: {sum(batch['total_pages'] for batch in batches)}")

    try:
        total_start_time = time.time()
        overall_stats = {
            'total_files_processed': 0,
            'total_pages_processed': 0,
            'total_files_generated': 0,
            'batch_count': len(batches)
        }

        print(f"\nğŸ”„ å¼€å§‹åˆ†æ‰¹å¤„ç†...")
        print(f"åç«¯: {backend}")

        # é€æ‰¹å¤„ç†
        for batch_idx, batch in enumerate(batches, 1):
            print(f"\n--- å¤„ç†æ‰¹æ¬¡ {batch_idx}/{len(batches)} ---")
            print(f"æ–‡ä»¶: {len(batch['files'])} ä¸ª")
            print(f"é¡µæ•°: {batch['total_pages']} é¡µ")
            print(f"æ–‡ä»¶å: {', '.join(batch['file_names'])}")

            # å‡†å¤‡PDFæ•°æ®
            pdf_bytes_list = []
            pdf_file_names = batch['file_names']

            print(f"ğŸ“– åŠ è½½æ‰¹æ¬¡ {batch_idx} PDFæ–‡ä»¶...")
            for pdf_path in batch['files']:
                pdf_bytes = read_fn(pdf_path)
                pdf_bytes = convert_pdf_bytes_to_bytes_by_pypdfium2(pdf_bytes, 0, None)
                pdf_bytes_list.append(pdf_bytes)
                print(f"  âœ… {pdf_path.name}")

            # åˆ›å»ºå›¾åƒå†™å…¥å™¨
            image_writers = []
            output_dirs = []

            print(f"ğŸ“ å‡†å¤‡æ‰¹æ¬¡ {batch_idx} è¾“å‡ºç›®å½•...")
            for pdf_file_name in pdf_file_names:
                local_image_dir, local_md_dir = prepare_env(output_base_dir / pdf_file_name, pdf_file_name, "vlm")
                image_writer = FileBasedDataWriter(local_image_dir)
                image_writers.append(image_writer)
                output_dirs.append((local_image_dir, local_md_dir))
                print(f"  ğŸ“‚ {pdf_file_name}: {local_md_dir}")

            print(f"ğŸ”„ å¤„ç†æ‰¹æ¬¡ {batch_idx}...")
            batch_start_time = time.time()

            # ä½¿ç”¨batch_doc_analyzeæ‰¹é‡å¤„ç†
            all_middle_json, _ = batch_doc_analyze(
                pdf_bytes_list=pdf_bytes_list,
                image_writer_list=image_writers,
                backend=backend[4:],  # å»æ‰"vlm-"å‰ç¼€
                server_url=None
            )

            batch_end_time = time.time()
            batch_processing_time = batch_end_time - batch_start_time

            print(f"âœ… æ‰¹æ¬¡ {batch_idx} å¤„ç†å®Œæˆ! ç”¨æ—¶: {batch_processing_time:.2f} ç§’")

            # ç»Ÿè®¡å½“å‰æ‰¹æ¬¡ç»“æœ
            batch_pages_processed = 0
            batch_files_generated = 0

            for i, (pdf_file_name, middle_json) in enumerate(zip(pdf_file_names, all_middle_json)):
                if isinstance(middle_json, dict) and "pdf_info" in middle_json:
                    pages = len(middle_json["pdf_info"])
                    batch_pages_processed += pages
                    print(f"  ğŸ“„ {pdf_file_name}: {pages} é¡µ")

                    # ç»Ÿè®¡ç”Ÿæˆçš„æ–‡ä»¶æ•°é‡
                    local_image_dir, local_md_dir = output_dirs[i]
                    if Path(local_md_dir).exists():
                        output_files = list(Path(local_md_dir).rglob("*"))
                        batch_files_generated += len(output_files)
                        print(f"     ç”Ÿæˆæ–‡ä»¶: {len(output_files)} ä¸ª")

            # æ›´æ–°æ€»ä½“ç»Ÿè®¡
            overall_stats['total_files_processed'] += len(batch['files'])
            overall_stats['total_pages_processed'] += batch_pages_processed
            overall_stats['total_files_generated'] += batch_files_generated

            print(f"ğŸ“Š æ‰¹æ¬¡ {batch_idx} ç»Ÿè®¡:")
            print(f"  å¤„ç†æ–‡ä»¶: {len(batch['files'])} ä¸ª")
            print(f"  å¤„ç†é¡µæ•°: {batch_pages_processed} é¡µ")
            print(f"  ç”Ÿæˆæ–‡ä»¶: {batch_files_generated} ä¸ª")
            print(f"  å¤„ç†é€Ÿåº¦: {batch_pages_processed/batch_processing_time:.2f} é¡µ/ç§’")

        total_end_time = time.time()
        total_processing_time = total_end_time - total_start_time

        print(f"\nğŸ‰ æ‰€æœ‰æ‰¹æ¬¡å¤„ç†å®Œæˆ!")
        print(f"\nğŸ¯ æ€»ä½“æ€§èƒ½ç»Ÿè®¡:")
        print(f"  å¤„ç†PDFæ•°é‡: {overall_stats['total_files_processed']} ä¸ª")
        print(f"  æ€»æ‰¹æ¬¡æ•°: {overall_stats['batch_count']}")
        print(f"  æ€»é¡µæ•°: {overall_stats['total_pages_processed']}")
        print(f"  æ€»å¤„ç†æ—¶é—´: {total_processing_time:.2f} ç§’")
        print(f"  å¹³å‡æ¯PDF: {total_processing_time/overall_stats['total_files_processed']:.2f} ç§’")
        print(f"  å¹³å‡æ¯é¡µ: {total_processing_time/overall_stats['total_pages_processed']:.2f} ç§’")
        if overall_stats['total_pages_processed'] > 0:
            print(f"  å¤„ç†é€Ÿåº¦: {overall_stats['total_pages_processed']/total_processing_time:.2f} é¡µ/ç§’")
        print(f"  æ€»ç”Ÿæˆæ–‡ä»¶: {overall_stats['total_files_generated']} ä¸ª")
        print(f"  å¹³å‡æ¯æ‰¹æ¬¡: {total_processing_time/overall_stats['batch_count']:.2f} ç§’")

        # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
        results_file = output_base_dir / "batch_results.txt"
        with open(results_file, 'w', encoding='utf-8') as f:
            f.write(f"åˆ†æ‰¹å¤„ç†æµ‹è¯•ç»“æœ\n")
            f.write(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"æ‰¹æ¬¡å¤§å°: {batch_size} é¡µ/æ‰¹æ¬¡\n")
            f.write(f"æ€»æ‰¹æ¬¡æ•°: {overall_stats['batch_count']}\n")
            f.write(f"å¤„ç†æ–‡ä»¶æ•°: {overall_stats['total_files_processed']}\n")
            f.write(f"æ€»å¤„ç†æ—¶é—´: {total_processing_time:.2f} ç§’\n")
            f.write(f"å¹³å‡æ¯PDF: {total_processing_time/overall_stats['total_files_processed']:.2f} ç§’\n")
            f.write(f"å¤„ç†é€Ÿåº¦: {overall_stats['total_pages_processed']/total_processing_time:.2f} é¡µ/ç§’\n")
            f.write(f"æ€»ç”Ÿæˆæ–‡ä»¶: {overall_stats['total_files_generated']} ä¸ª\n")

        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {results_file}")
        print(f"ğŸ è¾“å‡ºç›®å½•: {output_base_dir}")
        print(f"ğŸ‰ åˆ†æ‰¹å¤„ç†æµ‹è¯•å®Œæˆ!")

    except Exception as e:
        print(f"âŒ åˆ†æ‰¹å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()